{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import Counter\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data: ./train.tsv\n",
    "# test data:     ./test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                             review\n",
      "0          0  Leaks: Liss seems to be totally incompetent: m...\n",
      "1          1  Replacement Peeler: Loved my old one. Loaned i...\n",
      "2          0  Not what I was expecting: I chose to rate this...\n",
      "3          1  Watch face is hard to read: Although I don't o...\n",
      "4          0  Disappointing: I was eager to read this book s...\n",
      "...      ...                                                ...\n",
      "29991      1  Love EW: I must admit that I am a total TV afi...\n",
      "29992      1  Easy to follow and delicious recipes!: I compl...\n",
      "29993      1  The Beauty and Mystery of Veronique: Perhaps t...\n",
      "29994      1  I love it.: Brilliant, hilarious, quick and ea...\n",
      "29995      0  broken...: bad choice...2d film would not play...\n",
      "\n",
      "[29996 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./train.tsv', sep = '\\t')\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 23997\n",
      "validation set size: 5999\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8 # 80% for training, 20% for validation\n",
    "random_seed = 100\n",
    "\n",
    "train_dataframe = dataframe.sample(frac=train_ratio, random_state=random_seed)\n",
    "valid_dataframe = dataframe.drop(train_dataframe.index)\n",
    "print('training set size:', len(train_dataframe))\n",
    "print('validation set size:', len(valid_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                             review\n",
      "0        1  Human Hurricane!: Would you like to sleep in t...\n",
      "1        2  A Mom: I bought this with all kinds of expecta...\n",
      "2        3  Good Read: I judge all books that I read by a ...\n",
      "3        4  It's awesome: DVD set is exactly what you'd bu...\n",
      "4        5  Great Movie!!!: This definatly the best Godzil...\n",
      "...    ...                                                ...\n",
      "5995  5996  Beautiful and Spiritual: This is a very beauti...\n",
      "5996  5997  Another Cash In: This cd is pure dreck and it'...\n",
      "5997  5998  Concept drawings-very good: The concept drawin...\n",
      "5998  5999  I hear i all the time is awsome: this is great...\n",
      "5999  6000  Not so great Performance: This mouse is very s...\n",
      "\n",
      "[6000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dataframe = pd.read_csv('./test.tsv', sep = '\\t')\n",
    "print (test_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the trivial baseline: predict the majority label of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 11965, 1: 12032})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_dataframe['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority guess accuracy: 0.5099183197199533\n"
     ]
    }
   ],
   "source": [
    "# Looks like label 1 has slightly more counts than label 0 in training data\n",
    "# So the 'majority guess' prediction is an array filled with 1s\n",
    "majority_guess_pred = [1 for i in range(len(valid_dataframe))]\n",
    "accuracy = accuracy_score(valid_dataframe['label'], majority_guess_pred)\n",
    "print ('Majority guess accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: write out prediction values into a csv format file\n",
    "# params:\n",
    "#     df: dataframe, where each row is a test example, with column 'id' as data id\n",
    "#     pred: a list or 1-d array of prediction values\n",
    "#     filepath: the output file path\n",
    "# return:\n",
    "#     None\n",
    "\n",
    "def write_test_prediction(df, pred, filepath):\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        outfile.write('{},{}\\n'.format('id', 'label'))\n",
    "        for index, row in df.iterrows():\n",
    "            outfile.write('{},{}\\n'.format(row['id'], pred[index]))\n",
    "    print (len(df), 'predictions are written to', filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 predictions are written to ./majority_guess.csv\n"
     ]
    }
   ],
   "source": [
    "majority_guess_pred_test = [1 for i in range(len(test_dataframe))]\n",
    "write_test_prediction(test_dataframe, majority_guess_pred_test, './majority_guess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use all unigrams from training data as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 3))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "vectorizer.fit(train_dataframe['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract feature vectors for training, validation, and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23997, 1949941)\n",
      "(5999, 1949941)\n",
      "(6000, 1949941)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "train_X = vectorizer.transform(train_dataframe['review'])\n",
    "valid_X = vectorizer.transform(valid_dataframe['review'])\n",
    "test_X = vectorizer.transform(test_dataframe['review'])\n",
    "\n",
    "train_X_standard=MaxAbsScaler().fit(train_X).transform(train_X)\n",
    "valid_X_standard=MaxAbsScaler().fit(valid_X).transform(valid_X)\n",
    "test_X_standard=MaxAbsScaler().fit(test_X).transform(test_X)\n",
    "#print (train_X.shape)\n",
    "#print (valid_X.shape)\n",
    "#print (test_X.shape)\n",
    "\n",
    "print (train_X_standard.shape)\n",
    "print (valid_X_standard.shape)\n",
    "print (test_X_standard.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.7, solver='liblinear')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regularized = LogisticRegression(penalty='l2',C = 1.7, solver='liblinear')\n",
    "model_regularized.fit(train_X_standard, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized logistic regression, accuracy on validation set: 0.9051508584764127\n"
     ]
    }
   ],
   "source": [
    "valid_Y_hat_regularized = model_regularized.predict(valid_X_standard)\n",
    "valid_Y = valid_dataframe['label'].to_numpy()\n",
    "accuracy = accuracy_score(valid_Y, valid_Y_hat_regularized)\n",
    "print ('Regularized logistic regression, accuracy on validation set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized logistic regression, accuracy on validation set: i= 0.1 , 0.9001500250041674\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.2 , 0.9034839139856643\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.30000000000000004 , 0.903817302883814\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.4 , 0.9034839139856643\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.5 , 0.9039839973328888\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.6 , 0.9039839973328888\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.7000000000000001 , 0.9043173862310385\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.8 , 0.9043173862310385\n",
      "Regularized logistic regression, accuracy on validation set: i= 0.9 , 0.9041506917819636\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.0 , 0.9043173862310385\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.1 , 0.9041506917819636\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.2000000000000002 , 0.9044840806801133\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.3000000000000003 , 0.9046507751291882\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.4000000000000001 , 0.904817469578263\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.5000000000000002 , 0.904817469578263\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.6 , 0.904984164027338\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.7000000000000002 , 0.9051508584764127\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.8000000000000003 , 0.904984164027338\n",
      "Regularized logistic regression, accuracy on validation set: i= 1.9000000000000001 , 0.904984164027338\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1, 2, 0.1):\n",
    "    model_reg = LogisticRegression(penalty='l2',C = i, solver='liblinear')\n",
    "    model_reg.fit(train_X_standard, train_Y)\n",
    "    valid_Y_hat_reg = model_reg.predict(valid_X_standard)\n",
    "    accuracy = accuracy_score(valid_Y, valid_Y_hat_reg)\n",
    "    print ('Regularized logistic regression, accuracy on validation set:', \"i=\",i,\",\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 predictions are written to ./logistic_reg_regression.csv\n"
     ]
    }
   ],
   "source": [
    "all_train_Y = dataframe['label']\n",
    "#all_train_X = vectorizer.transform(dataframe['review'])\n",
    "all_train_X_standard = MaxAbsScaler().fit(valid_X).transform((vectorizer.transform(dataframe['review'])))\n",
    "model_regularized.fit(all_train_X_standard, all_train_Y)\n",
    "test_Y_hat_regularized = model_regularized.predict(test_X_standard)\n",
    "write_test_prediction(test_dataframe, test_Y_hat_regularized, './logistic_reg_regression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, accuracy on validation set: 0.868144690781797\n",
      "Naive Bayes, accuracy on validation set: 0.8584764127354559\n",
      "Naive Bayes, accuracy on validation set: 0.8514752458743123\n",
      "Naive Bayes, accuracy on validation set: 0.8428071345224204\n",
      "Naive Bayes, accuracy on validation set: 0.8359726621103517\n",
      "Naive Bayes, accuracy on validation set: 0.8271378563093849\n",
      "Naive Bayes, accuracy on validation set: 0.8174695782630439\n",
      "Naive Bayes, accuracy on validation set: 0.8104684114019003\n",
      "Naive Bayes, accuracy on validation set: 0.8003000500083347\n",
      "Naive Bayes, accuracy on validation set: 0.7931321886981163\n",
      "Naive Bayes, accuracy on validation set: 0.786964494082347\n",
      "Naive Bayes, accuracy on validation set: 0.7799633272212035\n",
      "Naive Bayes, accuracy on validation set: 0.7711285214202367\n",
      "Naive Bayes, accuracy on validation set: 0.7612935489248208\n",
      "Naive Bayes, accuracy on validation set: 0.7526254375729288\n",
      "Naive Bayes, accuracy on validation set: 0.7442907151191865\n",
      "Naive Bayes, accuracy on validation set: 0.7342890481746958\n",
      "Naive Bayes, accuracy on validation set: 0.727621270211702\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1, 10, 0.5):\n",
    "    bnb = BernoulliNB(alpha=i)\n",
    "    bnb.fit(train_X_standard, train_Y)\n",
    "    valid_Y_hat_nb = bnb.predict(valid_X_standard)\n",
    "    accuracy = accuracy_score(valid_Y, valid_Y_hat_nb)\n",
    "    print ('Naive Bayes, accuracy on validation set:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor, accuracy on validation set: n= 1 , 0.5117519586597766\n",
      "K-Nearest Neighbor, accuracy on validation set: n= 2 , 0.49141523587264546\n",
      "K-Nearest Neighbor, accuracy on validation set: n= 3 , 0.518919819969995\n",
      "K-Nearest Neighbor, accuracy on validation set: n= 4 , 0.49874979163193867\n",
      "K-Nearest Neighbor, accuracy on validation set: n= 5 , 0.5242540423403901\n",
      "K-Nearest Neighbor, accuracy on validation set: n= 6 , 0.5522587097849642\n",
      "K-Nearest Neighbor, accuracy on validation set: n= 7 , 0.5175862643773962\n",
      "K-Nearest Neighbor, accuracy on validation set: n= 8 , 0.5327554592432072\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1,9,1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(train_X_standard, train_Y)\n",
    "    valid_Y_hat_knn = knn.predict(valid_X_standard)\n",
    "    accuracy = accuracy_score(valid_Y, valid_Y_hat_knn)\n",
    "    print ('K-Nearest Neighbor, accuracy on validation set:',\"n=\",i,\",\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC, accuracy on validation set: i= 0.01 , 0.9046507751291882\n",
      "SVC, accuracy on validation set: i= 0.012 , 0.9051508584764127\n",
      "SVC, accuracy on validation set: i= 0.014 , 0.9051508584764127\n",
      "SVC, accuracy on validation set: i= 0.016 , 0.9053175529254875\n",
      "SVC, accuracy on validation set: i= 0.018000000000000002 , 0.9051508584764127\n",
      "SVC, accuracy on validation set: i= 0.02 , 0.9053175529254875\n",
      "SVC, accuracy on validation set: i= 0.022 , 0.9053175529254875\n",
      "SVC, accuracy on validation set: i= 0.024 , 0.9054842473745625\n",
      "SVC, accuracy on validation set: i= 0.026000000000000002 , 0.9054842473745625\n",
      "SVC, accuracy on validation set: i= 0.028000000000000004 , 0.9058176362727122\n",
      "SVC, accuracy on validation set: i= 0.03 , 0.9061510251708618\n",
      "SVC, accuracy on validation set: i= 0.032 , 0.9066511085180864\n",
      "SVC, accuracy on validation set: i= 0.034 , 0.906984497416236\n",
      "SVC, accuracy on validation set: i= 0.036000000000000004 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.038 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.04 , 0.9071511918653109\n",
      "SVC, accuracy on validation set: i= 0.042 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.044000000000000004 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.046000000000000006 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.048 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.05 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.052000000000000005 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.054 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.056 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.058 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.060000000000000005 , 0.9071511918653109\n",
      "SVC, accuracy on validation set: i= 0.062000000000000006 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.064 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.066 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.068 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.06999999999999999 , 0.9074845807634606\n",
      "SVC, accuracy on validation set: i= 0.072 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.074 , 0.9071511918653109\n",
      "SVC, accuracy on validation set: i= 0.076 , 0.9071511918653109\n",
      "SVC, accuracy on validation set: i= 0.078 , 0.9071511918653109\n",
      "SVC, accuracy on validation set: i= 0.08 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.082 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.08399999999999999 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.086 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.088 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.09 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.092 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.094 , 0.9073178863143857\n",
      "SVC, accuracy on validation set: i= 0.096 , 0.9071511918653109\n",
      "SVC, accuracy on validation set: i= 0.09799999999999999 , 0.906984497416236\n",
      "SVC, accuracy on validation set: i= 0.09999999999999999 , 0.906984497416236\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.01,0.1,0.002):\n",
    "    SVC = LinearSVC(max_iter=6000, C=i)\n",
    "    SVC.fit(train_X_standard, train_Y)\n",
    "    valid_Y_hat_SVC = SVC.predict(valid_X_standard)\n",
    "    accuracy = accuracy_score(valid_Y, valid_Y_hat_SVC)\n",
    "    print ('SVC, accuracy on validation set:',\"i=\",i,\",\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC, accuracy on validation set: i= 0.05 , 0.8809801633605601\n",
      "SVC, accuracy on validation set: i= 0.060000000000000005 , 0.8856476079346558\n",
      "SVC, accuracy on validation set: i= 0.07 , 0.8879813302217037\n",
      "SVC, accuracy on validation set: i= 0.08000000000000002 , 0.8909818303050508\n",
      "SVC, accuracy on validation set: i= 0.09000000000000001 , 0.892982163693949\n",
      "SVC, accuracy on validation set: i= 0.1 , 0.895149191531922\n",
      "SVC, accuracy on validation set: i= 0.11000000000000001 , 0.8968161360226704\n",
      "SVC, accuracy on validation set: i= 0.12000000000000001 , 0.8971495249208201\n",
      "SVC, accuracy on validation set: i= 0.13 , 0.8971495249208201\n",
      "SVC, accuracy on validation set: i= 0.14 , 0.8961493582263711\n",
      "SVC, accuracy on validation set: i= 0.15000000000000002 , 0.8969828304717453\n",
      "SVC, accuracy on validation set: i= 0.16000000000000003 , 0.8963160526754459\n",
      "SVC, accuracy on validation set: i= 0.17000000000000004 , 0.8959826637772962\n",
      "SVC, accuracy on validation set: i= 0.18000000000000005 , 0.8954825804300717\n",
      "SVC, accuracy on validation set: i= 0.19 , 0.8953158859809969\n",
      "SVC, accuracy on validation set: i= 0.2 , 0.8959826637772962\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.05,0.2,0.01):\n",
    "    SVC = LinearSVC(penalty='l1',loss='squared_hinge',max_iter=6000, C=i,dual=False)\n",
    "    SVC.fit(train_X_standard, train_Y)\n",
    "    valid_Y_hat_SVC = SVC.predict(valid_X_standard)\n",
    "    accuracy = accuracy_score(valid_Y, valid_Y_hat_SVC)\n",
    "    print ('SVC, accuracy on validation set:',\"i=\",i,\",\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC, accuracy on validation set: 0.9074845807634606\n"
     ]
    }
   ],
   "source": [
    "SVC = LinearSVC(max_iter=6000, C=0.042)\n",
    "SVC.fit(train_X_standard, train_Y)\n",
    "valid_Y_hat_SVC = SVC.predict(valid_X_standard)\n",
    "accuracy = accuracy_score(valid_Y, valid_Y_hat_SVC)\n",
    "print ('SVC, accuracy on validation set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 predictions are written to ./svc_regression.csv\n"
     ]
    }
   ],
   "source": [
    "SVC.fit(all_train_X_standard, all_train_Y)\n",
    "test_Y_hat_svc = SVC.predict(test_X_standard)\n",
    "write_test_prediction(test_dataframe, test_Y_hat_svc, './svc_regression.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
